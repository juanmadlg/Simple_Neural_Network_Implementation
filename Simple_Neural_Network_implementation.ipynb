{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Neural Network implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq9vxwBV1Nmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import exp, array, random, dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGnxEATR1dfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork():\n",
        "  \n",
        "  def __init__(self):\n",
        "    random.seed(1)\n",
        "    \n",
        "    # Neural Network with 4 nodes in the Layer 0, 6 in the hidden layer and 1 in the output layer\n",
        "    # Assing initial random weights to the 4x6 and 6x1 matrix with values between -1 and 1 (mean 0)\n",
        "    # random.random generates values in range [0.0, 1.0)\n",
        "    self.synaptic_weights_l0 = 2 * random.random((4, 6)) - 1\n",
        "    self.synaptic_weights_l1 = 2 * random.random((6, 1)) - 1\n",
        "    \n",
        "  @staticmethod\n",
        "  def _sigmoid(x):\n",
        "    return 1 / (1 + exp(-x))\n",
        "  \n",
        "  \n",
        "  # This is the gradient of the Sigmoid curve. \n",
        "  # It indicates how confident we are about the existing weight\n",
        "  \n",
        "  @staticmethod\n",
        "  def _sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "  \n",
        "  \n",
        "  def train(self, X, y, number_of_training_iterations):\n",
        "    \n",
        "\n",
        "    for iteration in range(number_of_training_iterations):\n",
        "      \n",
        "\n",
        "      # Calculates predictions from X and current weights\n",
        "      l1, l2 = self.think(X)\n",
        "      \n",
        "      # Loss function and optimization for the last layer\n",
        "      l2_error = y - l2\n",
        "      l2_delta = l2_error * self._sigmoid_derivative(l2)\n",
        "      \n",
        "      if iteration % 1000 == 0:\n",
        "        print(f\"Loss: {l2_error}\")\n",
        "      \n",
        "      # Loss function - error propaged to the next layer and optimization\n",
        "      l1_error = dot(l2_delta, self.synaptic_weights_l1.T)\n",
        "      l1_delta = l1_error * self._sigmoid_derivative(l1)\n",
        "      \n",
        "      # Apply correction to the weights\n",
        "      self.synaptic_weights_l0 += dot(X.T, l1_delta)\n",
        "      self.synaptic_weights_l1 += dot(l1.T, l2_delta)\n",
        "    \n",
        "  def think(self, X):\n",
        "    # Calculates predictions from X and current weights\n",
        "    l1 = self._sigmoid(dot(X, self.synaptic_weights_l0))\n",
        "    l2 = self._sigmoid(dot(l1, self.synaptic_weights_l1))\n",
        "    \n",
        "    return l1, l2\n",
        "  \n",
        "  def predict(self, X):\n",
        "    l1, l2 = self.think(X)\n",
        "    return l2\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GZHeDHy8-ig",
        "colab_type": "code",
        "outputId": "8bc3347b-56fd-4f16-9559-5844e4295304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  nn = NeuralNetwork()\n",
        "  \n",
        "  # Training Set Data - True if first and last values are different\n",
        "  X = array([[0, 0, 1, 1], [1, 1, 1, 0], [1, 0, 1,0],[0, 1, 1,1],[1, 1, 1,1],[0, 1, 1,1],[0, 0, 0, 0],[1,0,0,0],[0,0,0,1]])\n",
        "  y = array([[1,1,1,1,0,1,0,1,1]]).T\n",
        "  \n",
        "  nn.train(X, y, 10000)\n",
        "  \n",
        "  true_value = array([0, 1, 0, 1])\n",
        "  print(f\"Prediction for {true_value} is {nn.predict(true_value)}\")\n",
        "\n",
        "  false_value = array([0, 1, 0, 0])\n",
        "  print(f\"Prediction for {false_value} {nn.predict(false_value)}\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: [[ 0.56290547]\n",
            " [ 0.42540429]\n",
            " [ 0.41319053]\n",
            " [ 0.56552181]\n",
            " [-0.49481697]\n",
            " [ 0.56552181]\n",
            " [-0.48577078]\n",
            " [ 0.43905495]\n",
            " [ 0.62061088]]\n",
            "Loss: [[ 0.01304291]\n",
            " [ 0.03481366]\n",
            " [ 0.0098664 ]\n",
            " [ 0.02857414]\n",
            " [-0.05514936]\n",
            " [ 0.02857414]\n",
            " [-0.05232056]\n",
            " [ 0.03210371]\n",
            " [ 0.03541152]]\n",
            "Loss: [[ 0.00937409]\n",
            " [ 0.0222668 ]\n",
            " [ 0.00678769]\n",
            " [ 0.01836948]\n",
            " [-0.03452158]\n",
            " [ 0.01836948]\n",
            " [-0.03423826]\n",
            " [ 0.02056135]\n",
            " [ 0.02264236]]\n",
            "Loss: [[ 0.00778607]\n",
            " [ 0.01752669]\n",
            " [ 0.005548  ]\n",
            " [ 0.01447091]\n",
            " [-0.02690629]\n",
            " [ 0.01447091]\n",
            " [-0.0272127 ]\n",
            " [ 0.01616293]\n",
            " [ 0.01779716]]\n",
            "Loss: [[ 0.00683593]\n",
            " [ 0.01487826]\n",
            " [ 0.00482824]\n",
            " [ 0.01228673]\n",
            " [-0.02270447]\n",
            " [ 0.01228673]\n",
            " [-0.02324   ]\n",
            " [ 0.0137027 ]\n",
            " [ 0.01509142]]\n",
            "Loss: [[ 0.00618246]\n",
            " [ 0.01313635]\n",
            " [ 0.00434178]\n",
            " [ 0.01084885]\n",
            " [-0.019964  ]\n",
            " [ 0.01084885]\n",
            " [-0.02060773]\n",
            " [ 0.01208491]\n",
            " [ 0.01331357]]\n",
            "Loss: [[ 0.00569611]\n",
            " [ 0.01188149]\n",
            " [ 0.00398392]\n",
            " [ 0.00981268]\n",
            " [-0.01800197]\n",
            " [ 0.00981268]\n",
            " [-0.01870146]\n",
            " [ 0.01092013]\n",
            " [ 0.01203405]]\n",
            "Loss: [[ 0.00531514]\n",
            " [ 0.01092317]\n",
            " [ 0.00370598]\n",
            " [ 0.00902133]\n",
            " [-0.01651081]\n",
            " [ 0.00902133]\n",
            " [-0.01723976]\n",
            " [ 0.01003118]\n",
            " [ 0.01105774]]\n",
            "Loss: [[ 0.00500582]\n",
            " [ 0.01016093]\n",
            " [ 0.00348176]\n",
            " [ 0.00839195]\n",
            " [-0.01532942]\n",
            " [ 0.00839195]\n",
            " [-0.01607333]\n",
            " [ 0.0093246 ]\n",
            " [ 0.01028178]]\n",
            "Loss: [[ 0.00474788]\n",
            " [ 0.00953621]\n",
            " [ 0.00329577]\n",
            " [ 0.00787616]\n",
            " [-0.01436431]\n",
            " [ 0.00787616]\n",
            " [-0.01511471]\n",
            " [ 0.00874586]\n",
            " [ 0.00964624]]\n",
            "Prediction for [0 1 0 1] is [0.98805126]\n",
            "Prediction for [0 1 0 0] [0.01318574]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}